---
title: "네이버 검색 DevOps 에이전트: LLM 기반 장애 대응 자동화 구축 사례"
date: 2026-02-17 20:49:30 -0500
categories:
  - blog
tags:
  - LLM DevOps 에이전트
  - 장애 대응 자동화
  - 네이버 검색 아키텍처
  - AI 기반 모니터링
  - DevOps LLM 적용
  - 인시던트 관리 시스템
  - SRE 자동화
layout: single
author_profile: true
read_time: true
comments: false
share: false
related: true
---

# 네이버 검색의 DevOps 에이전트: LLM으로 더 빠르고 스마트한 장애 대응 구축하기

새벽 2시, 네이버 검색 시스템에서 동시다발적으로 알림이 발생합니다. 응답 시간 증가, 상태 코드 이상, 리소스 사용량 급증. 게이트웨이부터 통합 검색 서버, PRS/SaaS 레이어를 거쳐 웹, 이미지, 뉴스 등 수십 개의 도메인별 서버에 이르는 복잡한 아키텍처에서 한 계층의 장애는 순식간에 다른 계층으로 번져 나갑니다. 

전통적인 대응 방식에서는 경험 많은 IC(Incident Commander)가 여러 모니터링 시스템을 오가며 데이터를 수집하고, 계층별 담당자들과 협업하며, 무엇이 진짜 문제인지 파악해야 했습니다. 이 과정은 느리고, 리소스 집약적이며, 무엇보다 사람에게 지나치게 의존적이었습니다.

네이버 검색팀은 이러한 한계를 돌파하기 위해 LLM 기반 DevOps 에이전트를 구축했습니다. 단순히 알림을 요약하는 도구가 아니라, 알림 수신부터 데이터 수집, 진단, 리포트 생성까지 인간 IC의 워크플로우를 그대로 모방하면서도 1분 내에 장애 범위와 원인을 파악하는 시스템입니다. 이 글에서는 네이버 검색이 V1 아키텍처에서 V2로 진화하며 어떻게 단순 자동화에서 LLM 주도 오케스트레이션으로 나아갔는지, 그 과정에서 얻은 엔지니어링 인사이트를 살펴봅니다.

## 전통적인 장애 대응의 고충

네이버 검색 규모에서 장애 대응이 어려운 이유는 단순히 시스템이 크기 때문만은 아닙니다. 알림이 동시다발적으로 발생하지만, 각 알림이 담고 있는 의미는 제각각입니다. 일시적인 트래픽 증가로 인한 응답 지연인지, 실제 서버 장애인지, 남용 트래픽에 의한 문제인지 즉시 판단하기 어렵습니다. 

경험 많은 IC라도 새벽 시간 반복되는 거짓 긍정 알림(false positive)에 지치게 되고, 진짜 중요한 신호를 놓칠 위험이 커집니다.

더 큰 문제는 데이터가 여러 모니터링 시스템에 흩어져 있다는 점입니다. 통합 검색 서버 상태는 Usain에서, 도메인별 서버 응답 시간과 상태 코드는 Gom과 Prometheus에서, 인프라 리소스와 다운스트림 API 헬스 체크는 또 다른 시스템에서 확인해야 합니다. 각 계층은 서로 다른 팀이 담당하고 있어, 효과적인 진단을 위해서는 광범위한 팀 간 협업이 필요합니다. 

문제는 이러한 지식이 경험 많은 IC 개인에게 축적될 뿐, 인력이 교체되거나 순환 근무할 때 제대로 전달되지 않는다는 것입니다.

긴급성 판단 역시 까다롭습니다. 일시적인 느려짐이나 짧은 남용 트래픽 급증도 동일한 알림을 발생시킵니다. IC는 매번 알림이 올 때마다 "이것이 정말 개입이 필요한 상황인가?"를 고민하며 여러 대시보드를 확인해야 하고, 이는 특히 근무 외 시간에 극심한 피로를 초래합니다. 네이버 검색팀은 이러한 문제를 해결하기 위해 LLM 에이전트라는 새로운 접근법을 시도했습니다.

## DevOps 에이전트 설계 목표

DevOps 에이전트의 핵심 목표는 명확했습니다. 알림 발생 후 1분 내에 장애의 범위와 성격을 파악하는 것. 이는 단순히 빠른 응답을 넘어, 알림의 심각도를 정확히 분류해 IC 피로도를 줄이고, 특히 근무 외 시간의 불필요한 개입을 최소화하겠다는 의도를 담고 있습니다.

더 중요한 것은 지속 가능성입니다. 분석된 모든 장애가 향후 에이전트의 역량을 강화하는 자산이 되어야 하며, 일회성 도구가 아닌 계속 발전하는 시스템을 만들고자 했습니다. 

이를 위해 에이전트는 인간 IC의 워크플로우를 면밀히 재현해야 했습니다. 알림을 받고, 분석하고, 여러 소스에서 관련 데이터를 수집하고, 상황을 진단한 뒤, 종합된 리포트를 생성하는 전 과정을 자동화하는 것이 설계의 출발점이었습니다.

## V1 아키텍처: 구조화된 오케스트레이션과 병렬 서브 에이전트

V1 아키텍처는 명확한 구조화와 병렬 처리를 통해 목표를 달성하고자 했습니다. 먼저 전처리기(pre-processor)가 다양한 모니터링 소스에서 들어오는 원시 알림을 구조화된 형태로 변환합니다. 영향받는 영역, 타임스탬프, 관찰된 현상 등을 정형화함으로써 IC 에이전트가 일관된 입력을 받을 수 있도록 합니다.

IC 에이전트는 이 구조화된 데이터를 받아 여러 서브 에이전트를 병렬로 호출합니다.

- **NX 에이전트**: 통합 검색 서버의 상태를 점검합니다
- **PRS 에이전트**: 도메인 레벨의 응답 시간, 상태 코드, 리소스 사용량을 분석합니다
- **인프라 에이전트**: 인프라 리소스 상태와 다운스트림 API 헬스를 확인합니다
- **변경 및 배포 조사 에이전트**: 임베딩 기반 검색을 통해 최근 배포, A/B 테스트 등 시스템 변경 사항을 찾아냅니다

각 서브 에이전트는 내부 메트릭 시스템인 Usain, Gom, Prometheus 등에서 데이터를 수집하고, LLM을 사용해 영향도를 평가한 뒤 IC 에이전트에게 결과를 보고합니다. 최종적으로 서머라이저가 각 서브 에이전트의 리포트를 종합해 최종 평가를 생성합니다. 장애가 진행 중인지 해결되었는지, 심각도는 어느 정도인지 색상 코드로 표시하고, 가능한 근본 원인 가설을 제시합니다.

### 기술 스택

소프트웨어 스택은 Python 기반 에이전트 서버에 OpenAI Agent SDK, GPT-4.1과 GPT-5 모델, 그리고 OpenAI 임베딩 모델을 사용합니다. 팀은 향후 내부 모델로 마이그레이션하고 자체 구축한 LangSmith 스타일의 트레이싱 대시보드를 도입할 계획입니다.

## 핵심 엔지니어링 기법

V1 구현 과정에서 팀이 고안한 몇 가지 엔지니어링 기법은 특히 주목할 만합니다.

### 트리거 큐 메커니즘

비용과 효율성 양면에서 중요한 역할을 합니다. 동시다발적으로 발생하는 알림을 10초 윈도우 내에 배치 처리하며, 최대 30초까지 대기합니다. 이를 통해 알림 하나당 하나의 에이전트 실행이 아닌, 하나의 장애 상황당 하나의 실행으로 통합함으로써 LLM 호출 비용을 절감하고, 더 풍부한 컨텍스트로 진단 품질을 높입니다.

### 슬라이딩 윈도우 이상 탐지

노이즈가 많고 희박한 시계열 데이터를 다루는 데 효과적입니다. 2시간 베이스라인 데이터를 최근 10분 윈도우와 비교하며, 신뢰 구간을 활용해 더 정밀한 문제 식별을 가능하게 합니다. 단순 임계값 기반 알림보다 훨씬 강건하게 실제 이상을 포착할 수 있습니다.

### 평가 및 회귀 시스템

지속적인 개선을 뒷받침합니다. 모든 에이전트 실행에 대해 입력과 컨텍스트를 저장해두고, 프롬프트나 기능을 업데이트할 때마다 과거 장애를 재현해봄으로써 개선 사항을 검증하고 회귀를 조기에 발견합니다. 이는 에이전트가 진화하면서도 이전에 해결했던 문제를 다시 놓치지 않도록 보장합니다.

## V1의 한계와 V2로의 전환 필요성

V1은 명확한 성과를 냈지만, 동시에 근본적인 한계도 드러났습니다. 오케스트레이션이 하드코딩되어 있어 각 서브 에이전트는 정확히 한 번씩만 호출됩니다. 서브 에이전트들의 결론이 상충할 때 추가 질의를 통해 조율할 방법이 없습니다. 

LLM은 주로 이상 탐지와 요약에만 사용되며, 최신 모델들이 갖춘 강력한 추론과 계획 능력은 활용되지 않습니다.

더 중요한 것은 모델의 급속한 발전입니다. 프로젝트 시작 시점의 GPT-4에서 GPT-5에 이르기까지, 이전에는 불가능했던 에이전트 동작들이 이제는 거의 즉시 구현 가능해졌습니다. 하드코딩된 로직으로 고정된 V1 아키텍처는 이러한 모델 발전의 혜택을 충분히 누리지 못합니다. 팀은 V2 아키텍처를 통해 이러한 제약을 돌파하기로 결정했습니다.

## V2 아키텍처: LLM 주도 오케스트레이션과 멀티턴 추론

V2에서 IC 에이전트는 진정한 플래너가 됩니다. 어떤 도구와 서브 에이전트를 어떤 순서로 몇 번 호출할지, 진화하는 분석 상황에 따라 스스로 결정합니다. 서브 에이전트들은 호출 가능한 도구로 재구성되어, 초기 결과가 모호하거나 상충할 때 LLM이 조정된 파라미터로 재질의할 수 있는 멀티턴 인터랙션이 가능해집니다.

도구 생태계도 확장됩니다.

- 공휴일 및 국가 이벤트 감지기
- 외부 남용 모니터링 도구인 WTM
- mFront, NX Blocker 로그 분석
- 컴포넌트별 세밀한 헬스 분석

전처리기와 리포팅 파이프라인은 유지되지만, 핵심 인텔리전스 레이어는 코드 주도에서 모델 주도 오케스트레이션으로 전환됩니다.

이러한 변화는 단순히 더 많은 기능을 추가하는 것 이상의 의미를 갖습니다. 에이전트가 상황에 따라 동적으로 조사 방향을 조정하고, 초기 가설이 틀렸을 때 다른 각도로 접근하며, 여러 서브 에이전트의 상충하는 정보를 추가 데이터 수집을 통해 해소할 수 있게 됩니다. 이는 숙련된 IC가 장애를 조사하는 방식에 훨씬 더 가깝습니다.

## 미래 로드맵: 진단에서 자율적 복구로

네이버 검색팀의 비전은 진단을 넘어 복구까지 확장됩니다.

### 알림의 재정의

첫 번째 목표는 알림을 스트레스가 아닌 가치 있는 정보로 재정의하는 것입니다. 더 많은 알림이 발생해도 인간의 피로도 증가 없이 에이전트에게는 더 풍부한 컨텍스트를 제공하게 됩니다.

### 지식 축적 메커니즘

분석된 장애는 검색 가능한 컨텍스트로 아카이빙됩니다. 새로운 장애가 발생하면 에이전트는 과거 유사 사례를 검색해 더 빠르고 정확한 진단을 수행합니다. 이는 조직의 장애 대응 노하우를 에이전트가 축적하고 활용하는 메커니즘이 됩니다.

### 자율적 복구

더 나아가 에이전트는 구체적인 복구 조치를 권장합니다. 역사적 패턴을 기반으로 남용 상황에서는 WTM 규칙 조정을, 다운스트림 장애 시에는 재시도 빈도 감소를 제안하는 식입니다. 장기적으로는 인간의 승인 하에 에이전트가 복구 조치를 자율적으로 실행하는 단계를 목표로 합니다.

### 컨텍스트 업데이트 에이전트

동시에 컨텍스트 업데이트 에이전트를 별도로 개발 중입니다. 네이버 검색 아키텍처는 지속적으로 진화하므로, DevOps 에이전트가 항상 최신의 정확한 시스템 지식을 바탕으로 작동하도록 보장하는 것이 필수적입니다. 이 컴패니언 에이전트는 시스템 변화를 추적하고 DevOps 에이전트의 지식 베이스를 업데이트하는 역할을 담당합니다.

## DevOps에 LLM 에이전트를 적용하는 교훈

네이버 검색의 여정은 LLM 에이전트를 운영 환경에 도입하려는 조직에 실용적인 경로를 보여줍니다. 수동 IC 워크플로우에서 V1의 구조화된 자동화를 거쳐 V2의 모델 주도 오케스트레이션으로 진화하는 과정은, 한 번에 도약하기보다는 단계적으로 역량을 쌓아가는 접근법의 중요성을 강조합니다.

성공의 핵심 요소는 명확합니다.

- 알림을 배치 처리해 효율성을 높이고
- 평가 시스템을 구축해 지속적인 개선을 가능하게 하며
- 모델 역량이 발전함에 따라 진화할 수 있도록 설계하는 것

특히 V1에서 V2로의 전환은 초기에 보수적으로 시작하더라도, 모델이 개선되면 더 야심찬 아키텍처로 이동할 준비를 해야 함을 보여줍니다.

이 DevOps 에이전트는 장애 대응을 고도로 숙련된 전문가에게만 의존하는 스트레스 높은 프로세스에서, 체계적이고 지식을 축적하는 역량으로 전환시켰습니다. 알림이 발생할 때마다 새벽에 깨어나 여러 대시보드를 확인하던 IC는 이제 에이전트가 1분 만에 생성한 종합 리포트를 받아 신속하게 판단할 수 있습니다. 더 중요한 것은, 매 장애가 에이전트를 더 똑똑하게 만드는 학습 기회가 된다는 점입니다.

### 실전 적용을 위한 가이드

LLM 에이전트를 DevOps에 도입하고자 하는 팀에게 네이버 검색의 사례는 분명한 메시지를 전합니다.

완벽한 솔루션을 처음부터 만들려 하지 말고, 인간 전문가의 워크플로우를 면밀히 모방하는 것에서 시작하세요. 평가와 회귀 테스트 시스템을 초기부터 구축해 개선을 측정하고 검증할 수 있게 하세요. 그리고 모델 발전에 맞춰 아키텍처가 진화할 수 있도록 유연성을 확보하세요. 

장애 대응은 결국 인간의 전문성을 대체하는 것이 아니라, 그들이 더 높은 수준의 판단과 의사결정에 집중할 수 있도록 지원하는 도구를 만드는 일입니다.