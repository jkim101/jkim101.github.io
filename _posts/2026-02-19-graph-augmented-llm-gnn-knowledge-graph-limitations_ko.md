---
title: "그래프 증강 LLM: GNN과 지식 그래프로 한계 해결하는 법"
date: 2026-02-19 23:40:26 -0500
categories:
  - blog
tags:
  - 그래프 증강 LLM
  - GraphRAG
  - 지식 그래프
  - 그래프 신경망
  - LLM 한계
  - RPG-Encoder
  - 코드 이해
  - RAG 시스템
  - 토큰 효율성
layout: single
author_profile: true
read_time: true
comments: false
share: false
related: true
---

# 그래프 증강 LLM: 그래프 신경망과 지식 그래프가 LLM의 근본적 한계를 해결하는 방법

대규모 언어 모델이 수천억 개의 파라미터를 넘어서며 계속 성장하고 있지만, 여전히 특정 유형의 문제 앞에서는 무력하게 무너집니다. 관계 추론이나 구조적 이해가 필요한 질문들 앞에서 말입니다. 더 많은 데이터를 학습시키거나 모델 크기를 키운다고 해서 해결되지 않는 문제들입니다.

최근 두 가지 중요한 연구 결과가 독립적으로 같은 답에 도달했습니다. 그래프 유저 그룹(GUG)의 실증적 GraphRAG 실험과 마이크로소프트의 RPG-Encoder 논문은 모두 하나의 통찰을 공유합니다. 그래프 구조야말로 LLM을 현실에 연결하는 잃어버린 퍼즐 조각이라는 것입니다. 이 글에서는 두 접근법을 면밀히 분석하여 언제, 어떻게 그래프가 LLM을 증강해야 하는지에 대한 통합 프레임워크를 제시합니다.

## GraphRAG 실험: 예상과 다른 결과

그래프 유저 그룹은 엄격하게 통제된 환경에서 흥미로운 실험을 수행했습니다. H100 GPU에서 gpt-oss-120B 모델을 사용해 50개의 질문에 대해 텍스트 RAG, 그래프 RAG(LPG와 RDF), 그리고 바닐라 LLM을 비교했습니다.

결과는 예상과 다른 면이 있었습니다. 전체적으로는 텍스트 RAG가 F1 스코어 0.189로 선두를 차지했고, 그래프 RAG는 LPG가 0.163, RDF가 0.152로 뒤따랐습니다. 바닐라 LLM은 0.143으로 가장 낮았습니다.

하지만 질문별 세부 분석을 들여다보면 전혀 다른 그림이 드러납니다. 그래프 RAG는 전체 질문의 45%에서 승리했습니다. 특히 관계형 또는 구조적 쿼리에서 월등한 성능을 보였습니다. 예를 들어 이연 수익과 상품권 부채 간의 관계를 묻는 질문에서는 그래프가 압도적이었습니다. 반면 텍스트 RAG는 특정 숫자 값이 필요한 질문에서 강세를 보였습니다.

이 결과가 시사하는 바는 명확합니다. 우리는 그래프와 텍스트 중 하나를 선택할 필요가 없습니다. 질문 유형에 따라 지능적으로 라우팅하는 시스템이 필요합니다.

더욱 흥미로운 발견은 바닐라 LLM이 10.2%의 경우에서 승리했다는 점입니다. 이는 주입된 컨텍스트가 오히려 성능을 해칠 수 있음을 보여줍니다. 모델이 이미 충분한 사전 학습 지식을 가지고 있을 때 불필요한 추가 정보는 노이즈가 될 수 있습니다.

## 숨겨진 병목: 토큰 효율성

그러나 GraphRAG의 진짜 병목은 눈에 잘 보이지 않는 곳에 있습니다. 바로 토큰 효율성입니다.

RDF 표현은 URI 접두사에 무려 57.8%의 토큰을 낭비합니다. 예를 들어 `fibo-fnd-acc-4217:` 같은 긴 접두사가 반복적으로 나타나면서 동일한 LPG 트리플에 비해 1.73배 많은 토큰을 소비합니다. 이는 어텐션 밀도를 LPG의 16.3%에서 RDF의 10.6%로 직접적으로 감소시킵니다.

LPG도 완벽하지 않습니다. 약 10%의 토큰이 None 엔티티 간 엣지에 낭비됩니다. Revenue Recognition이 APPLIES_TO를 통해 None과 연결되는 식입니다. 이런 엣지는 정보를 전혀 담고 있지 않습니다.

이 발견의 핵심 통찰은 토큰 레벨의 정보 밀도가 RAG 성능을 결정한다는 것입니다. 이는 온톨로지 구축과 그래프 스키마 설계가 단순한 모델링 선택이 아니라 일급 엔지니어링 과제임을 의미합니다. 데이터 과학자들은 종종 그래프 구조의 의미론적 풍부함에만 집중하지만, 실제로는 토큰 효율성이라는 하드웨어 제약이 시스템 전체의 성능을 좌우합니다.

### 온톨로지 설계 시 고려사항

온톨로지를 설계할 때 각 트리플이 얼마나 많은 토큰을 소비하는지, 얼마나 많은 정보 밀도를 제공하는지를 측정하고 최적화해야 합니다.

## 그래프 토폴로지의 함정

그래프 구조 자체에도 숨겨진 함정이 있습니다. 두 그래프 모두 극단적인 스타 토폴로지를 보입니다. 단일 허브 노드가 0.99 이상의 허브 스코어를 기록하며 전체 중개 중심성의 27.6%(LPG)와 19.3%(RDF)를 장악합니다.

이는 대부분의 쿼리가 동일한 슈퍼허브를 거쳐 간다는 의미입니다. 결과적으로 다양한 질문 유형에 걸쳐 중복된 컨텍스트가 포함되고 어텐션이 희석됩니다.

실무적으로 이는 프로덕션 GraphRAG 시스템이 허브 중심 토폴로지를 처리하기 위한 특화된 서브그래프 추출 전략과 GDBMS 검색 레이어의 확장성 기법을 필요로 합니다. 일반적인 k-hop 이웃 탐색으로는 슈퍼허브에서 너무 많은 노드가 선택되어 컨텍스트 윈도우가 즉시 포화됩니다.

## RPG-Encoder: 코드 이해와 생성의 통합

마이크로소프트의 RPG-Encoder는 완전히 다른 영역에서 그래프의 힘을 입증합니다. 코드 이해와 코드 생성을 거울상 프로세스로 재구성합니다. 설계 의도와 구현 사이의 동일한 변환을 반대 방향으로 수행하는 것으로 보는 것입니다.

이 두 작업을 단일 Repository Planning Graph로 통합합니다. 이 듀얼뷰 지식 그래프는 시맨틱 특성(코드가 무엇을 하는가)과 의존성 구조(코드가 어떻게 연결되는가)를 하나의 임베딩 공간에 결합합니다. 이는 AST만 사용하는 접근법(의미 없는 구조)과 의존성 그래프만 사용하는 접근법(의도 없는 연결)의 한계를 모두 극복합니다.

### 환각 제거의 구조적 접근

RPG-Encoder의 진정한 혁신은 환각을 줄이는 것이 아니라 환각이 발생할 조건 자체를 제거한다는 점입니다. LLM의 출력을 그래프에 존재하는 경로로 제약함으로써 구조적으로 유효한 코드만 생성되도록 합니다.

버그 위치 파악에서 93.7%, 재구성 정확도에서 98.5%를 달성한 것은 우연이 아닙니다. 모델이 그래프에 존재하지 않는 관계를 만들어낼 수 없기 때문입니다.

이는 통계적 패턴 매칭에 의존하는 순수 LLM 접근법과 근본적으로 다릅니다. 통계는 개연성을 제공하지만 보장은 하지 못합니다. 그래프 제약은 보장을 제공합니다.

## 동적 그래프 유지의 현실적 해법

실제 리포지토리와 지식 베이스는 정적이지 않습니다. 지속적으로 진화합니다. 이는 그래프 증강 LLM 시스템에 대한 가장 흔한 반론을 낳습니다. 대규모에서 고품질 그래프를 유지하는 것이 비현실적이라는 것입니다.

RPG-Encoder는 이 문제를 정면으로 다룹니다. 점진적 로컬 토폴로지 업데이트 전략을 통해 그래프 재구축 비용을 95.7% 감소시킵니다. 코드가 변경될 때 전체 그래프를 다시 빌드하는 대신 영향을 받는 부분만 선택적으로 업데이트합니다.

이는 코드를 넘어 모든 동적 지식 그래프에 적용 가능한 광범위한 엔지니어링 패턴을 반영합니다. 이 접근법이 왜 중요한가요? 많은 조직이 초기 그래프 구축은 가능하지만 지속적인 유지 보수 비용 때문에 그래프 기반