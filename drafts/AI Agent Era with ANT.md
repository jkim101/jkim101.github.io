# ðŸ’¡ The AI Agent Boom, Re-Examined Through a 30-Year-Old Sociological Theory

Without a doubt, the most significant topic in the AI scene today is the 'Agentic System.'
We are rapidly moving beyond AI that merely generates answers (Generative) to an era where AI acts autonomously (Agentic). These systems set their own goals, use tools (Function Calling), browse the internet, and interact with other systems to complete complex tasks.
As I watch this incredible technological leap, I'm reminded of a sociological framework from over 30 years ago, pioneered by Bruno Latour: Actor-Network Theory (ANT).

1. <b>  What is Actor-Network Theory (ANT)? </b>

ANT proposes that the power to act and shape the world does not belong to humans alone.
The core concept of this theory is 'symmetry.' It treats both humans and non-humans as equal 'actants.' These non-human actants can be anything: technology, objects, data, or even viruses.
ANT posits that our world is constructed through a process where these countless human and non-human actants form relationships (a 'network'), influencing and 'translating' each other's interests to 'enroll' them into achieving a goal.

2. <b>The AI Agent = The Rise of a Powerful 'Non-Human Actant'</b>

What happens when we view today's AI agents through this lens?
An AI agent is no longer a passive 'tool' that humans simply use. By autonomously calling APIs, querying databases, sending emails, and collaborating with other AI agents, it has become one of the most powerful 'non-human actants' to ever join our network.
What are the RAGs, multi-agent systems, and function-calling architectures we are building? They are precisely the mechanisms that allow this new AI actant to 'enroll' and 'translate' other actants (databases, APIs, legacy systems, PDF documents, and even 'me,' the human) into its network to achieve larger objectives.

3. <b>From 'Human-Centrism' to 'Network-Centrism'</b>

ANT fundamentally challenges human-centrism. Instead of asking, "Who is in control of the system?" ANT suggests we should ask, "How is this network stabilized and maintained?"
The emergence of agentic AI systems is shifting our role from 'Commander' to 'Network Orchestrator' or 'Goal Aligner.'
Our primary challenge is not to 'control' these powerful non-human actants, but rather to design how we build stable, reliable networks with them, ensuring we are aligned toward a common, well-defined goal.

ðŸ’¡ <b>Conclusion: We Are Welcoming a New Kind of 'Colleague'</b>
The 'Agentic System' boom may not just be about smarter technology.
It signals a fundamental redefinition of the relationship between us (human actants) and our technology (non-human actants).
Especially for those of us in data engineering and platforms, AI agents will soon become new 'colleague-actants,' working alongside data pipelines, quality systems, and human engineers to achieve the shared goal of "creating value from data."

How are you preparing to collaborate with your new non-human colleagues?